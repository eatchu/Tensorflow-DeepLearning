{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model overfitting solution\n",
    "  - Dropout 적용\n",
    "  - image 증식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model create\n",
      "image preprocessing\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential # keras model \n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D # Convolution layer\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten # Affine layer\n",
    "import os\n",
    "\n",
    "# dir setting\n",
    "base_dir = \"C:/IITT/6_Tensorflow/workspace/chap07_CNN/lecture_3_Cats_and_Dogs/cats_and_dogs\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "validation_dir = os.path.join(base_dir, 'validation_dir')\n",
    "\n",
    "# Hyper parameters\n",
    "img_h = 150 # height\n",
    "img_w = 150 # width\n",
    "input_shape = (img_h, img_w, 3) \n",
    "\n",
    "# 1. CNN Model layer \n",
    "print('model create')\n",
    "model = Sequential()\n",
    "\n",
    "# Convolution layer1 : kernel[3,3,3,32]\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',\n",
    "                 input_shape = input_shape))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# Convolution layer2 : kernel[3,3,32,64]\n",
    "model.add(Conv2D(64,kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# Convolution layer3 : kernel[5,5,64,128], maxpooling() 제외 \n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# Flatten layer :4d -> 2d\n",
    "model.add(Flatten()) \n",
    "# 2차 적용 : 드롭아웃 - 과적합 해결 \n",
    "model.add(Dropout(0.5)) # fully connected 층 이전에 배치 \n",
    "\n",
    "# Affine layer(Fully connected layer1) : [n, 256]\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "\n",
    "# Output layer(Fully connected layer2) : [256, 1]\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# model training set : Adam or RMSprop \n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'binary_crossentropy', # one hot encoding\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# 2. image file preprocessing : 이미지 제너레이터 이용  \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "print(\"image preprocessing\")\n",
    "\n",
    "# 1차 적용 \n",
    "#train_data = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 2차 적용 : image 증식 - 과적합 해결\n",
    "train_data = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range = 40, # image 회전 각도 범위(+, - 범위)\n",
    "        width_shift_range = 0.2, # image 수평 이동 범위\n",
    "        height_shift_range = 0.2, # image 수직 이용 범위  \n",
    "        shear_range = 0.2, # image 전단 각도 범위\n",
    "        zoom_range=0.2, # image 확대 범위\n",
    "        horizontal_flip=True,) # image 수평 뒤집기 범위 \n",
    "\n",
    "# 검증 데이터에는 증식 적용 안함 \n",
    "validation_data = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_data.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150,150),\n",
    "        batch_size=35, \n",
    "        class_mode='binary') # binary label\n",
    "# Found 2000 images belonging to 2 classes.\n",
    "\n",
    "validation_generator = validation_data.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150,150),\n",
    "        batch_size=35, # [수정] batch size 올림 \n",
    "        class_mode='binary')\n",
    "# Found 1000 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 81s 814ms/step - loss: 0.7158 - accuracy: 0.5113 - val_loss: 0.6881 - val_accuracy: 0.5510\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 66s 659ms/step - loss: 0.6855 - accuracy: 0.5478 - val_loss: 0.6715 - val_accuracy: 0.5464\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s 649ms/step - loss: 0.6589 - accuracy: 0.5950 - val_loss: 0.6557 - val_accuracy: 0.6352\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 67s 673ms/step - loss: 0.6631 - accuracy: 0.5899 - val_loss: 0.6373 - val_accuracy: 0.6294\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 67s 675ms/step - loss: 0.6436 - accuracy: 0.6141 - val_loss: 0.6200 - val_accuracy: 0.6663\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 67s 673ms/step - loss: 0.6128 - accuracy: 0.6584 - val_loss: 0.5540 - val_accuracy: 0.7193\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 67s 675ms/step - loss: 0.5969 - accuracy: 0.6781 - val_loss: 0.5692 - val_accuracy: 0.6876\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 68s 683ms/step - loss: 0.5793 - accuracy: 0.6957 - val_loss: 0.5462 - val_accuracy: 0.7199\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 66s 656ms/step - loss: 0.5941 - accuracy: 0.6833 - val_loss: 0.5511 - val_accuracy: 0.7130\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 66s 664ms/step - loss: 0.5831 - accuracy: 0.6814 - val_loss: 0.5229 - val_accuracy: 0.7239\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. model training : 배치 제너레이터 이용 모델 훈련 \n",
    "model_fit = model.fit_generator(\n",
    "          train_generator, \n",
    "          steps_per_epoch=100, \n",
    "          epochs=10, # 30 epochs()\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=50) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
