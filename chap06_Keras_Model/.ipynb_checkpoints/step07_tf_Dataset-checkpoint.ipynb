{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class\n",
    "  - dataset으로 부터 사용가능한 데이터를 메모리에 로딩가능\n",
    "  - batch size 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: ((2,), ()), types: (tf.float32, tf.float32)>\n",
      "x = [-0.3391899  -0.85999423], y = 0.45995643734931946\n",
      "x = [-0.05774602  0.4804866 ], y = 0.8368427157402039\n",
      "x = [0.9484875 1.3075742], y = 0.9203258156776428\n",
      "x = [0.91037256 1.249346  ], y = -0.16611215472221375\n",
      "x = [0.55195224 0.6796783 ], y = 0.007357328664511442\n"
     ]
    }
   ],
   "source": [
    "# 1. from_tensor_slices() : 입력 tensor로부터 slice 생성\n",
    "\n",
    "# 1) x, y 변수 정의\n",
    "x = tf.random.normal([5,2])\n",
    "y = tf.random.normal([5])\n",
    "\n",
    "# 2) Dataset : 5개 slice\n",
    "train_ds = Dataset.from_tensor_slices((x,y))\n",
    "print(train_ds)\n",
    "\n",
    "# 5개 관측치 -> 5개 slices\n",
    "for train_x, train_y in train_ds:\n",
    "    print(\"x = {}, y = {}\".format(train_x.numpy(), train_y.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: ((None, 2), (None,)), types: (tf.float32, tf.float32)>\n",
      "x = [[0.55195224 0.6796783 ]\n",
      " [0.9484875  1.3075742 ]], y = [0.00735733 0.9203258 ]\n",
      "x = [[-0.05774602  0.4804866 ]\n",
      " [ 0.91037256  1.249346  ]], y = [ 0.8368427  -0.16611215]\n",
      "x = [[-0.3391899  -0.85999423]], y = [0.45995644]\n"
     ]
    }
   ],
   "source": [
    "# 2. from_tensor_slices(x,y).shuffle(buffer size).batch(size)\n",
    "'''\n",
    "shuffle() : tensor 행단위 서플링\n",
    "     - buffer size : 선택된 data size\n",
    "batch() : model에 1회 공급할 dataset size\n",
    "ex) 60000(mnist) -> shuffle(10000).batch(100)\n",
    "    1번째 slice : 10000 data random 추출 후 서플링 -> 순서대로 100개 image 추출 -> 1회 공급 data\n",
    "    2번째 slice : next 10000 data random 추출 후 서플링 -> 100개 image 추출\n",
    "    ...\n",
    "    6번째 slice : next 10000 data random 추출 후 서플링 -> 100개 image 추출 -> 60000data 전체 사용\n",
    "'''\n",
    "\n",
    "# 1) x, y 변수 정의 \n",
    "x2 = tf.random.normal([5,2])\n",
    "y2 = tf.random.normal([5])\n",
    "\n",
    "# 2) Dataset : 5개 관측치 대상 2묶음 -> 3 slices\n",
    "train_ds2 = Dataset.from_tensor_slices((x,y)).shuffle(5).batch(2)\n",
    "print(train_ds2)\n",
    "\n",
    "# 3) 3 slice -> 1 slice\n",
    "for train_x, train_y in train_ds2:\n",
    "    print(\"x = {}, y = {}\".format(train_x.numpy(), train_y.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n",
      "slicing size = 500\n"
     ]
    }
   ],
   "source": [
    "# 3. keras dataset 적용\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "\n",
    "# 1) dataset load\n",
    "(x_train, y_train),(x_val, y_val) = load_data()\n",
    "\n",
    "x_train.shape\n",
    "y_train.shape\n",
    "\n",
    "# batch size = 100 image\n",
    "train_ds = Dataset.from_tensor_slices((x_train,y_train)).shuffle(1000).batch(100)\n",
    "\n",
    "cnt = 0\n",
    "for img, label in train_ds:\n",
    "    cnt += 1\n",
    "print(50000/100)\n",
    "print(\"slicing size = {}\".format(cnt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "문) MNIST 데이터셋을 이용하여 train_ds, val_ds 생성하기\n",
    "    train_ds : shuffle = 10000, batch = 32\n",
    "    val_ds : shuffle = 10000, batch = 32\n",
    "'''\n",
    "\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "x_train.shape # (60000, 28, 28)\n",
    "x_test.shape # (10000, 28, 28)\n",
    "\n",
    "train_ds = Dataset.from_tensor_slices((x_train,y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "cnt = 0\n",
    "for img, label in train_ds:\n",
    "    cnt += 1\n",
    "# slicing size = 1875        \n",
    "# 60000 = 1875 * 32    \n",
    "    \n",
    "val_ds = Dataset.from_tensor_slices((x_test,y_test)).shuffle(10000).batch(32)    \n",
    "    \n",
    "cnt = 0\n",
    "for img, label in val_ds:\n",
    "    cnt += 1\n",
    "# slicing size = 313    \n",
    "# 10000 = 32 * 313    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
