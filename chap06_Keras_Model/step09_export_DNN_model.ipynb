{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow 2.x 전문가용 DNN model 구축\n",
    "  - tensorflow2.0 저수준 API\n",
    "  - Dataset class 이용 : 공급 data 생성\n",
    "  - 순방향 step : 회귀방정식 연산 -> 예측치 -> loss\n",
    "  - 역방향 step : 자동미분계산 -> w, b update(model 최적화)\n",
    "  - 손실함수, 최적화, 모델평가 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # ver2.0\n",
    "from tensorflow.python.data import Dataset # dataset 생성\n",
    "from tensorflow.keras.layers import Dense, Flatten # layer 추가\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "from tensorflow.keras import datasets # mnist, cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. dataset load\n",
    "mnist = datasets.mnist\n",
    "(x_train,y_train),(x_val,y_val) = mnist.load_data()\n",
    "\n",
    "x_train.shape\n",
    "x_val.shape\n",
    "\n",
    "'''\n",
    "# image 2d -> 1d\n",
    "x_train = x_train.reshape(-1, 28*28)\n",
    "x_val = x_val.reshape(-1, 784)\n",
    "'''\n",
    "\n",
    "# image 정규화 -> 실수형\n",
    "x_train = x_train/225.\n",
    "x_val = x_val/225.\n",
    "\n",
    "# labels\n",
    "y_train # [5, 0, 4, ..., 5, 6, 8] : integer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Dataset 생성\n",
    "train_ds = Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "train_ds\n",
    "test_ds = Dataset.from_tensor_slices((x_val, y_val)).shuffle(10000).batch(32)\n",
    "test_ds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inputshape = (28,28)\n",
    "\n",
    "# 3. 순방향 step : 연산 -> (예측치 vs 관측치) -> loss\n",
    "# model class\n",
    "class Model(tf.keras.Model) :   # 자식 클ㄹ스(부모클래스)   \n",
    "    def __init__(self) :  # 생성자\n",
    "        super().__init__()  # 부모 생성자 호출\n",
    "        # x, b 자동 초기화. 따로 설정해주지 않아도 됨\n",
    "        # DNN layer\n",
    "        # 2d -> 1d\n",
    "        self.d0 = Flatten(input_shape=inputshape) # flatten layer\n",
    "        self.d1 = Dense(128, activation='relu')  # hidden layer 1\n",
    "        self.d2 = Dense(64, activation='relu')  # hidden layer2\n",
    "        self.d3 = Dense(10, activation='softmax')  # output layer\n",
    "    \n",
    "    def call(self, inputs) :  # 메서드 재정의\n",
    "        # 회귀방정식은 생략(자동으로 만들어짐)\n",
    "        x = self.d0(inputs)\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        return self.d3(x)  # 예측치(확률) 반환\n",
    "\n",
    "\n",
    "\n",
    "# 4. loss functin : 손실 함수 : 오차 반환\n",
    "loss = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# y_true (integer) vs y_pred(prop) : from_logits=True\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 손실이 작은 경우\n",
    "y_true = np.array([0,2]) # 정답 : 10진수\n",
    "y_pred = np.array([[0.9,0.02,0.08],[0.1,0.1,0.8]]) # 예측치 : 확률\n",
    "\n",
    "loss(y_true, y_pred).numpy() # 손실함수 : 0.6538635492324829\n",
    "  \n",
    "# 손실이 큰 경우\n",
    "y_true = np.array([0,1]) # 정답 : 10진수\n",
    "y_pred = np.array([[0.9,0.02,0.08],[0.1,0.1,0.8]]) # 예측치 : 확률\n",
    "\n",
    "loss(y_true, y_pred).numpy() # 손실함수 : 1.0038635730743408\n",
    "  \n",
    "\n",
    "\n",
    "# 5. model & optimizer\n",
    "model = Model()\n",
    "optimizer = optimizers.Adam()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 6. model 평가 : loss, accuracy -> 1 epoch 단위로 평가\n",
    "train_loss = metrics.Mean()  # loss mean\n",
    "train_acc = metrics.SparseCategoricalAccuracy()  # accuracy\n",
    "\n",
    "val_loss = metrics.Mean()  # loss mean\n",
    "val_acc = metrics.SparseCategoricalAccuracy()  # accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "epoch = 1, train loss = 1.560654, train acc = 0.911300, val loss = 1.513195, val acc = 0.950300\n",
      "epoch = 2, train loss = 1.535758, train acc = 0.932133, val loss = 1.511368, val acc = 0.951950\n",
      "epoch = 3, train loss = 1.524015, train acc = 0.942089, val loss = 1.506330, val acc = 0.956533\n",
      "epoch = 4, train loss = 1.516525, train acc = 0.948646, val loss = 1.504486, val acc = 0.958300\n",
      "epoch = 5, train loss = 1.511065, train acc = 0.953430, val loss = 1.501717, val acc = 0.960860\n",
      "epoch = 6, train loss = 1.507009, train acc = 0.957006, val loss = 1.501019, val acc = 0.961367\n",
      "epoch = 7, train loss = 1.503753, train acc = 0.959895, val loss = 1.499302, val acc = 0.962929\n",
      "epoch = 8, train loss = 1.501067, train acc = 0.962285, val loss = 1.498281, val acc = 0.963825\n",
      "epoch = 9, train loss = 1.498780, train acc = 0.964350, val loss = 1.497372, val acc = 0.964644\n",
      "epoch = 10, train loss = 1.496888, train acc = 0.966057, val loss = 1.496553, val acc = 0.965460\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 7. 역방향 step : 자동 미분계수\n",
    "@tf.function # 연산속도 향상\n",
    "def train_step(images, labels) :\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 1) 순방향 : loss 계산\n",
    "        preds = model(images) # model.call(images) : 예측치\n",
    "        loss_value = loss(labels, preds) # 손실함수 (y_true, y_pred)\n",
    "        \n",
    "        # 2) 역방향 : 손실값 -> [Model.W, Model.B]\n",
    "        grad = tape.gradient(loss_value, model.trainable_variables)\n",
    "        # 기울기 -> 최적화 객체 반영\n",
    "        optimizer.apply_gradients(zip(grad,model.trainable_variables))\n",
    "        \n",
    "        # 3) 1epoch -> loss, accuracy save\n",
    "        train_loss(loss_value) # loss mean\n",
    "        train_acc(labels, preds) # accuracy\n",
    "    \n",
    "\n",
    "@tf.function # 연산속도 향상\n",
    "def test_step(images, labels) :\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 1) 순방향 : loss 계산\n",
    "        preds = model(images) # model.call(images) : 예측치\n",
    "        loss_value = loss(labels, preds) # 손실함수 (y_true, y_pred)\n",
    "        \n",
    "        # 2) 역방향 : 없음\n",
    "        \n",
    "        # 3) 1epoch -> loss, accuracy save\n",
    "        val_loss(loss_value) # loss mean\n",
    "        val_acc(labels, preds) # accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 8. model training\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    \n",
    "    # model train\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "        \n",
    "    # model val\n",
    "    for images, labels in test_ds:\n",
    "        test_step(images, labels)\n",
    "        \n",
    "    form = \"epoch = {}, train loss = {:.6f}, train acc = {:.6f}, val loss = {:.6f}, val acc = {:.6f}\"\n",
    "    print(form.format(epoch+1, train_loss.result(),\n",
    "                      train_acc.result(),\n",
    "                      val_loss.result(),\n",
    "                      val_acc.result()))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
