{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.GradientTape + regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs = [2. 4. 6.]\n",
      "mse= 56.427795\n",
      "grad= [<tf.Tensor: id=88, shape=(1,), dtype=float32, numpy=array([-32.288425], dtype=float32)>, <tf.Tensor: id=78, shape=(1,), dtype=float32, numpy=array([-14.412262], dtype=float32)>]\n",
      "최초 손실값 : 56.427795\n",
      "w : [-0.59792495], b : [-2.0102808]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. input/output 변수 정의 \n",
    "inputs = tf.Variable([1.0,2.0,3.0]) # x변수 \n",
    "outputs = tf.Variable([2.0,4.0,6.0]) # y변수 \n",
    "print(\"outputs =\", outputs.numpy())   \n",
    "\n",
    "\n",
    "# 2. model : class 정의 \n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__() # 부모생성자 호출\n",
    "        self.W = tf.Variable(tf.random.normal([1])) # 기울기\n",
    "        self.B = tf.Variable(tf.random.normal([1])) # 절편\n",
    "    def call(self, inputs): # 메서드 재정의\n",
    "        return inputs * self.W + self.B # 회귀방정식 (예측치 반환)\n",
    "    \n",
    "# 3. 손실 함수 : 오차 반환 \n",
    "def loss(model, inputs, outputs):\n",
    "  err = model(inputs) - outputs # 예측치 - 정답 \n",
    "  return tf.reduce_mean(tf.square(err)) # MSE\n",
    "\n",
    "# 4. 미분계수(기울기) 계산  \n",
    "def gradient(model, inputs, outputs) :\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, outputs) # 손실함수 호출  \n",
    "        grad = tape.gradient(loss_value, [model.W, model.B]) \n",
    "        # 미분계수 -> 기울기와 절편 업데이트\n",
    "    return grad # 업데이트 결과 반환\n",
    "\n",
    "# 5. model 생성\n",
    "model = Model() # 생성자\n",
    "\n",
    "mse = loss(model, inputs, outputs)\n",
    "print(\"mse=\", mse.numpy())\n",
    "\n",
    "grad = gradient(model, inputs, outputs)\n",
    "print(\"grad=\",grad)\n",
    "\n",
    "# 6. model 최적화 객체\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "print(\"최초 손실값 : {:.6f}\".format(loss(model, inputs, outputs)))\n",
    "print(\"w : {}, b : {}\".format(model.W.numpy(), model.B.numpy()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step100 : loss = 0.011049\n",
      "step200 : loss = 0.006828\n",
      "step300 : loss = 0.004219\n",
      "최종 손실값 : 0.004219\n",
      "업데이트된 w : [2.0754414], b : [-0.17149581]\n",
      "y pred = [5.0171075]\n"
     ]
    }
   ],
   "source": [
    "# 7. 반복학습\n",
    "for step in range(300):\n",
    "        grad = gradient(model, inputs, outputs)  # 기울기 계산\n",
    "        # 기울기 -> 최적화객체 반영\n",
    "        opt.apply_gradients(zip(grad, [model.W, model.B]))\n",
    "        \n",
    "        if (step+1) % 100 == 0:\n",
    "            print(\"step{} : loss = {:.6f}\".format(step+1, loss(model, inputs, outputs)))\n",
    "\n",
    "\n",
    "# model 최적화\n",
    "print(\"최종 손실값 : {:.6f}\".format(loss(model, inputs, outputs)))\n",
    "print(\"업데이트된 w : {}, b : {}\".format(model.W.numpy(), model.B.numpy()))\n",
    "    \n",
    "\n",
    "# model test\n",
    "y_pred = model.call(2.5)\n",
    "print(\"y pred =\", y_pred.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
