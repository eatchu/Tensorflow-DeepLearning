{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN model + MNIST + Hyper parameters\n",
    "\n",
    " - Network layer\n",
    "   - input nodes : 28x28 = 784\n",
    "   - hidden1 nodes = 128 - 1층\n",
    "   - hidden2 nodes = 64 - 2층\n",
    "   - output nodes = 10 - 3층\n",
    "\n",
    " - Hyper parameters\n",
    "   - lr : 학습율\n",
    "   - epoch(generation) : 전체 dataset 재사용 횟수\n",
    "   - batch size : 1회 data 공급 횟수(mini batch)\n",
    "   - iter size : 반복횟수\n",
    "   - 1 epoch(60,000) : batch size(200) * iter size(300)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 1. MNIST dataset load\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train.shape  # (60000, 28, 28)  : images(픽셀)\n",
    "y_train.shape  # (60000,)  : labels(10진수)\n",
    "\n",
    "# 첫 번째 image 확인\n",
    "plt.imshow(x_train[0])  # 5\n",
    "plt.show()\n",
    "\n",
    "y_train[0]  # 5  : 10진수\n",
    "x_train[0]\n",
    "\n",
    "# images 정규화\n",
    "x_train_nor, x_test_nor = x_train/255.0, x_test/255.0\n",
    "x_train_nor[0]\n",
    "x_test_nor[0]\n",
    "\n",
    "# 3dim -> 2dim\n",
    "x_train_nor = x_train_nor.reshape(-1, 784)  # 784 =28 * 28\n",
    "x_test_nor = x_test_nor.reshape(-1, 784)\n",
    "\n",
    "x_train_nor.shape  # (60000, 784)\n",
    "x_test_nor.shape  # (10000, 784)\n",
    "\n",
    "# label 전처리\n",
    "# 1) 1dim -> 2dim\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "# 2) one-hot encoding\n",
    "obj = OneHotEncoder()\n",
    "y_train_one = obj.fit_transform(y_train).toarray()\n",
    "y_test_one = obj.fit_transform(y_test).toarray()\n",
    "y_train_one.shape  # (60000, 10)\n",
    "y_test_one.shape  # (10000, 10)\n",
    "\n",
    "\n",
    "# X, Y 변수 정의\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 784])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, 10])\n",
    "\n",
    "\n",
    "# Hyper parameters\n",
    "lr = 0.01\n",
    "epochs = 20\n",
    "batch_size = 200\n",
    "iter_size = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-7201eea0008c>:32: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "epoch1 : loss = 16.84944469134013\n",
      "epoch2 : loss = 1.6053912949562072\n",
      "epoch3 : loss = 1.436315072774887\n",
      "epoch4 : loss = 1.277008885939916\n",
      "epoch5 : loss = 1.1244391212860743\n",
      "epoch6 : loss = 0.9888953373829523\n",
      "epoch7 : loss = 0.8211476119359334\n",
      "epoch8 : loss = 0.7222996877630552\n",
      "epoch9 : loss = 0.6514275400837263\n",
      "epoch10 : loss = 0.6987380955616633\n",
      "epoch11 : loss = 0.6696098838249842\n",
      "epoch12 : loss = 0.8089819166064263\n",
      "epoch13 : loss = 0.7900441992282867\n",
      "epoch14 : loss = 0.7333843996127446\n",
      "epoch15 : loss = 0.778984272480011\n",
      "epoch16 : loss = 0.7489999404549599\n",
      "epoch17 : loss = 0.6944647692640622\n",
      "epoch18 : loss = 0.6814601132273674\n",
      "epoch19 : loss = 0.7243947091698647\n",
      "epoch20 : loss = 0.7136899170279503\n",
      "accuracy = 0.7999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#############################################\n",
    "# DNN network\n",
    "#############################################\n",
    "hidden1_nodes = 128\n",
    "hidden2_nodes = 64 \n",
    "\n",
    "# hidden layer 1\n",
    "w1 = tf.Variable(tf.random_normal([784,hidden1_nodes]))\n",
    "b1 = tf.Variable(tf.random_normal([hidden1_nodes]))\n",
    "\n",
    "hidden1_layer = tf.nn.relu(tf.matmul(X, w1) + b1)\n",
    "\n",
    "# hidden layer 2\n",
    "w2 = tf.Variable(tf.random_normal([hidden1_nodes, hidden2_nodes]))\n",
    "b2 = tf.Variable(tf.random_normal([hidden2_nodes]))\n",
    "\n",
    "hidden2_layer = tf.nn.relu(tf.matmul(hidden1_layer, w2) + b2)\n",
    "\n",
    "# hidden layer 3 : model 생성\n",
    "w3 = tf.Variable(tf.random_normal([hidden2_nodes, 10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "model = tf.matmul(hidden2_layer, w3) + b3\n",
    "\n",
    "\n",
    "# 5. softmax 알고리즘\n",
    "# (1) softmax\n",
    "softmax = tf.nn.softmax(model)  # 활성함수\n",
    "\n",
    "# (2) loss function : Softmax + Cross Entropy\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels = Y, logits = model))  # logit은 모델 역할. 활성함수가 없는 모델을 넣으면 자동으로 활성함수에 넣어줌.\n",
    "\n",
    "# (3)\n",
    "train = tf.train.AdamOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# (4) encoding -> decoding\n",
    "y_pred = tf.argmax(softmax, axis=1)\n",
    "y_true = tf.argmax(Y, axis=1)\n",
    "\n",
    "\n",
    "# 6. model training\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    feed = {X : x_train_nor, Y : y_train_one}\n",
    "    \n",
    "    # 반복학습 epochs = 20\n",
    "    # 1 epoch = 200개 이미지 * 300회 공급 = 60000장\n",
    "    for epoch in range(epochs) :  # 1세대\n",
    "        tot_loss = 0\n",
    "        \n",
    "        for step in range(iter_size) :  # 300 반복 학습\n",
    "            idx = np.random.choice(a=y_train_one.shape[0], size=batch_size, replace=False)  # y_train_one.shape[0] = 60000\n",
    "            \n",
    "            # Mini batch dataset\n",
    "            feed = {X:x_train_nor[idx], Y:y_train_one[idx]}\n",
    "            _, loss_val = sess.run([train, loss], feed_dict=feed)\n",
    "            \n",
    "            tot_loss += loss_val\n",
    "            \n",
    "        # 1epoch 종료\n",
    "        avg_loss = tot_loss / iter_size  # loss의 총합 / loss 수\n",
    "        print(\"epoch{} : loss = {}\".format(epoch+1, avg_loss))\n",
    "            \n",
    "            \n",
    "    # model test\n",
    "    feed2 = {X:x_test_nor, Y:y_test_one}\n",
    "    y_pred_re = sess.run(y_pred, feed_dict=feed2)\n",
    "    y_true_re = sess.run(y_true, feed_dict=feed2)\n",
    "    \n",
    "    acc = accuracy_score(y_true_re, y_pred_re)\n",
    "    print(\"accuracy =\", acc)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
