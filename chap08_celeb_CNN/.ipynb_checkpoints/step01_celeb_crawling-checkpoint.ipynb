{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install selenium\n",
    " - chromedriver download 버전 : 83.0.4103.97(64비트)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Jupyter_Notebook\\tensorflow\\chap08_celeb_CNN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlretrieve # server image -> local save\n",
    "import os # dir 경로/생성/이동\n",
    "import numpy as np\n",
    "\n",
    "pwd = os.getcwd() # 현재 경로 \n",
    "print(pwd) # C:\\IITT\\6_Tensorflow\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def celeb_crawler(name) : \n",
    "    # 1. dirver 경로/파일 지정 \n",
    "    driver = webdriver.Chrome(\"C:\\\\IITT\\\\6_Tensorflow\\\\workspace\\\\chap08_celeb_CNN\\\\lecture01_image_crawling\\\\chromedriver.exe\")\n",
    "    \n",
    "    # 2. 이미지 검색 url \n",
    "    driver.get(\"https://www.google.co.kr/imghp?hl=ko\")\n",
    "    \n",
    "    # 3. 검색 입력상자 tag -> 검색어 입력   \n",
    "    search_box = driver.find_element_by_name('q') # element 이름 찾기 \n",
    "    '''\n",
    "    find_element_by_name('name') : element name 속성 이름으로 찾기 \n",
    "    find_element_by_id('id') : element id 속성의 이름으로 찾기 \n",
    "    find_element_by_xpath('//tag[@속성='값']/tag') : tab의 계층적 구조로 찾기 \n",
    "    '''\n",
    "    search_box.send_keys(name) # 검색어 키보드 입력(driver 객체 member) \n",
    "    driver.implicitly_wait(3) # 3초 대기(자원 loading)\n",
    "    \n",
    "    # 4. [검색] 버튼 클릭 (\"//tag[@attr='value']/sub element\")\n",
    "    driver.find_element_by_xpath(\"//div[@id='sbtc']/button\").click() \n",
    "    \n",
    "    '''\n",
    "    <div jsname=\"BN6WQc\">\n",
    "       <div data-ri=\"0\"> : 첫번째 image\n",
    "       <div data-ri=\"4\"> : 다섯번째 image\n",
    "    '''    \n",
    "    image_url = []\n",
    "     \n",
    "    i=0 # 첫번째 이미지    \n",
    "    base = f\"//div[@data-ri='{i}']\"\n",
    "    driver.find_element_by_xpath(base).click() # image click\n",
    "    # click image url \n",
    "    src = driver.page_source # 현재 page html source\n",
    "    html = BeautifulSoup(src, \"html.parser\")\n",
    "    img_tag = html.select(\"img[class='rg_i Q4LuWd']\") # list\n",
    "    print(img_tag)\n",
    "    \n",
    "    for tag in img_tag : \n",
    "        if 'data-src' in str(tag) :\n",
    "            url = tag['data-src'] # dict\n",
    "            image_url.append(url)\n",
    "    \n",
    "    # image url 생성             \n",
    "    print(len(image_url)) # 6\n",
    "    image_url = np.unique(image_url) # 중복 url  삭제 \n",
    "    print(image_url)\n",
    "    \n",
    "    # url -> image save\n",
    "    for i in range(len(image_url)) :\n",
    "        try : # 예외처리 : server file 없음 예외처리 \n",
    "            file_name = \"test\"+str(i+1)+\".jpg\" # test1.jsp\n",
    "            # server image -> file save\n",
    "            urlretrieve(image_url[i], filename=file_name)\n",
    "        except :\n",
    "            print('해당 url에 image 없음 : ', i+1)        \n",
    "            \n",
    "    driver.close()\n",
    "    \n",
    "# 함수 test     \n",
    "#celeb_crawler(\"강호동\")   \n",
    "\n",
    "# 함수 호출 : 각 셀럼당 6개 이미지 \n",
    "namelist = [\"송강호\",'하정우','전지현']\n",
    "\n",
    "for name in namelist :\n",
    "    pwd = os.getcwd() # 현재 경로 \n",
    "    os.mkdir(name) # 현재 위치에 폴더 생성 \n",
    "    os.chdir(pwd+\"/\"+name) # lecture/하정우\n",
    "    celeb_crawler(name) # image crawling\n",
    "    os.chdir(pwd) # 원래 위치 이동 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
